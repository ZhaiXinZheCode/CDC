# CDC  
（Composite Data Chunk）

---

### 1. このアイデアはなぜ生まれたのか？

モデルの学習が終わるたびに、同じフォルダに次の4つのファイルが残ります。

```
best_model.pth      # 重み
train_config.yaml   # ハイパーパラメータ
loss_log.csv        # 損失ログ
loss_curve.png      # 可視化グラフ
```

他人に再現してもらう、あるいは2か月後に自分で再開するために、これら4ファイルをまとめて zip/tar で固め、アップロードし、展開します。  
tar/zip は確かに使えるものの、どうも気持ち悪いのです：

- オーバーフィットを確認したいだけなのに、500 MB のまるごとアーカイブを落とさなければならない。  
- 学習率だけ `train_config.yaml` で変えたいのに、500 MB の `best_model.pth` を毎回再パックしなければならない。  
- README に毎回「4ファイルを同じフォルダへ配置してください」と書くのが本当に面倒。  

そこで閃いたのは：  
4つのファイルを「一つにくっつけて」、かつ Python のスライスみたいに「欲しいものだけ取り出せる」方法はないか？  

CDC の出発点は、学習後のゴミ拾いに苛立つ自分への処方箋にすぎません。

---

### 2. 設計思想 / 哲学 / 目標  
（初版）

1. **3日で手書きパーサーを書けるほどミニマル**  
   Python 初心者が長い週末に書けなければ、フォーマットは重すぎる。  
   一瞥で把握できる複雑さに留める：開始マーカー＋長さ＋データペイロード、それだけ。

2. **人が読みやすく ≈ 機械も解析しやすい**  
   16進ダンプでファイル名が見えて、UTF-8文字列が読めて、PNGシグネチャがわかる。  
   IDE を開かずとも `hexdump -C` でデバッグできる。

3. **チェックサム/暗号化/署名は「オプションで楽を」**  
   アルゴリズムを内蔵しない。ただ**メタデータ用テキストスロット**を確保。  
   チェックサムが欲しければ JSON 一行を投げる：`{"md5":"...","algo":"CRC32"}`。  
   暗号化したい？ Python2行で鍵を同じスロットへ。  
   いらない？空欄にしておけばファイルは開く。

4. **専門は専門フォーマットに任せる**  
   CDC は圧縮もエンコード変換もデータベースインデックスも行わない。  
   異なるフォーマットを順番に貼り合わせるだけ。  
   PNG は PNG のまま、PyTorch は `.pth` のまま。接着剤に徹する。

5. **自由でオープン**  
   マジックヘッダなし、著作権バイトなし、強制バージョン番号なし。  
   誰でもフォークして独自方言を作り、いつでも本流に戻れる。

6. **ワンライナーで使える**  
   ワンコマンドで4つの学習成果を一つに固め、  
   ワンライナーで任意のファイルを取り出し、  
   Python の `zipfile` みたいなインフラとして振る舞い、新たな負荷にならない。

> これらは「方向宣言」にすぎません。  
> 8バイト長にするか、ディレクトリインデックスを付けるか、ストリーム再生に対応するかは議論のうえ決める。  
> 理想すぎると思ったら Issue でガツンと来てください。

---

### 3. 現状

- フォーマット仕様書： v0.1 ドラフト（まだ凍結前）  
- Python リファレンス実装：「パック→アンパック」が動くデモ版  
- 性能テストなし、他言語実装なし、実ユーザなし

「学習後の4ファイルイライラ」を「動くプロトタイプ」に変えたばかり。  
これから公開して叩いてもらいます。

---

### フォーマット仕様（ドラフト）

```
[FF] // チャンク開始マーカー(CSM)
  [E0][00 00 00][00 00 00 00 00 00 00 0A]Hello World // UTF-8テキストセグメント
  [EF][00 00 00][00 00 00 00 00 00 01 00]...        // バイナリセグメント(256 B)
[FF] // CSM
  ...
```

#### 用語早見表

| 構成要素           | 日本語名     | 英語名                     | 略称 |
|--------------------|--------------|----------------------------|------|
| 全体構造           | 複合データ塊 | Composite Data Chunk       | CDC  |
| 開始識別子         | ブロック開始記号 | Chunk Start Marker     | CSM  |
| データ単位         | データセグメント | Data Segment           | DS   |
| テキスト単位       | テキストセグメント | Text Segment         | TS   |
| バイナリ単位       | バイナリセグメント | Binary Segment       | BS   |
| テキストエンコードフィールド | テキストエンコードフラグ | Text Encoding Flag | TEF |
| バイナリメタフィールド | 予約パディング領域 | Reserved Padding Field | RPF |
| 長さフィールド     | データ長宣言 | Data Length Declaration    | DLD  |
| 実データ本体       | データペイロード | Data Payload          | DP   |

#### コア構造（調整歓迎）

```
+------+----------------+----------------------+----------------+
| フラグ | メタ(3B)       | データ長(8B, BE)     | ペイロード(可変) |
+------+----------------+----------------------+----------------+
```

- **テキストセグメント(TS):**  
  `[0xE0][TEF (3B)][DLD (8B)][UTF-8テキスト]`

- **バイナリセグメント(BS):**  
  `[0xEF][RPF (3B)][DLD (8B)][生バイナリ]`

#### タイプ表（拡張可）

| 3バイトタグ | カテゴリ | フォーマット |
|-------------|----------|--------------|
| **テキスト (00 xx xx)** |
| `00 00 00`  | テキスト | UTF-8        |
| `00 00 01`  | テキスト | ASCII        |
| …           | …        | …            |
| **バイナリ (FF xx xx)** |
| `FF 00 02`  | バイナリ | PNG          |
| `FF 00 09`  | バイナリ | ZIP          |
| …           | …        | …            |

---

### 使用例

テスト環境  
| ハードウェア | モデル |
|--------------|--------|
| CPU          | Intel Core i3-10100 @ 3.6 GHz |
| RAM          | 24 GB DDR4-2133 |
| SSD          | Great Wall P300 M.2 2 TB PCIe 3.0 |

#### エンコード

```python
import os, pathlib, time, json, hashlib
import YAF  # CDCライブラリ

def file_info(path):
    p = pathlib.Path(path).expanduser().resolve()
    st = p.stat()
    return {
        "name": p.name,
        "size_MB": st.st_size / 1024**2,
        "mtime": st.st_mtime,
        "md5": hashlib.md5(p.read_bytes()).hexdigest()
    }

writer = YAF.CdcEncoder("example.cdc")

big = file_info("bigFile")
pic = file_info("pic.png")

t0 = time.time()

writer.add_CSM([json.dumps(big), "bigfile", "バイナリテスト"])
writer.add_CSM([json.dumps(pic), "pic.png", "画像テスト"])
writer.add_CSM(["プレーンテキストサンプル"])

writer.flush()

print("エンコード %.2f 秒" % (time.time() - t0))
```

実行結果
```
{'name': 'bigFile', 'size_MB': 1100.0, ...} {'name': 'pic.png', 'size_MB': 2.17, ...}
エンコード 5.51 秒
```

#### デコード

```python
import YAF, time

t0 = time.time()
reader = YAF.CdcDecoder("example.cdc")
bundles = reader.decode(use_bitrange=True)  # 大容量ファイルをストリーム読み

print("デコード %.6f 秒" % (time.time() - t0))

for ds in bundles:
    print("+" * 20)
    for item in ds:
        print(f"\t{type(item)} : {item}")
```

実行結果
```
デコード 0.003990 秒
++++++++++++++++++++
	<class 'str'> : {"name":"bigFile", ...}
	<class 'YAF.BitRange'> : <BufferedReader>[296:1153433896]
	<class 'str'> : バイナリテスト
...
```

---

### マイクロベンチマーク（非常に初期段階）

#### エンコード

| ファイル | サイズ | 時間 | スピード |
|----------|--------|------|----------|
| B0.bin   | 362 MB | 676 ms | 535 MB/s |
| … 99 ファイル … |

平均 458 ms/ファイル

#### デコード

| ファイル | サイズ | 時間 | スピード |
|----------|--------|------|----------|
| encoded_B0.bin | 362 MB | 385 ms | 941 MB/s |
| … 99 ファイル … |

平均 181 ms/ファイル

#### 往復整合性検証

100 / 100 ファイルが bit-perfect に一致。

---

*CDC はまだ粘土のような段階です——壊して、形を変えて、スルーしても自由です。*
